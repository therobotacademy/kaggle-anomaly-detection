{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT Number of rows for aggregated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "import os\n",
    "\n",
    "# List all files under the input directory\n",
    "#path = '/kaggle'\n",
    "path = './'\n",
    "input_path  = path + '/input/gearbox-fault-diagnosis/'\n",
    "output_path = path + '/input/gearbox-fault-diagnosis-stdev/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read datasets\n",
    "## Healthy gearbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "h30hz0  = pd.read_csv(input_path + \"/Healthy/h30hz0.csv\")\n",
    "h30hz10 = pd.read_csv(input_path + \"/Healthy/h30hz10.csv\")\n",
    "h30hz20 = pd.read_csv(input_path + \"/Healthy/h30hz20.csv\")\n",
    "h30hz30 = pd.read_csv(input_path + \"/Healthy/h30hz30.csv\")\n",
    "h30hz40 = pd.read_csv(input_path + \"/Healthy/h30hz40.csv\")\n",
    "h30hz50 = pd.read_csv(input_path + \"/Healthy/h30hz50.csv\")\n",
    "h30hz60 = pd.read_csv(input_path + \"/Healthy/h30hz60.csv\")\n",
    "h30hz70 = pd.read_csv(input_path + \"/Healthy/h30hz70.csv\")\n",
    "h30hz80 = pd.read_csv(input_path + \"/Healthy/h30hz80.csv\")\n",
    "h30hz90 = pd.read_csv(input_path + \"/Healthy/h30hz90.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broken gearbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "b30hz0  = pd.read_csv(input_path + \"/BrokenTooth/b30hz0.csv\")\n",
    "b30hz10 = pd.read_csv(input_path + \"/BrokenTooth/b30hz10.csv\")\n",
    "b30hz20 = pd.read_csv(input_path + \"/BrokenTooth/b30hz20.csv\")\n",
    "b30hz30 = pd.read_csv(input_path + \"/BrokenTooth/b30hz30.csv\")\n",
    "b30hz40 = pd.read_csv(input_path + \"/BrokenTooth/b30hz40.csv\")\n",
    "b30hz50 = pd.read_csv(input_path + \"/BrokenTooth/b30hz50.csv\")\n",
    "b30hz60 = pd.read_csv(input_path + \"/BrokenTooth/b30hz60.csv\")\n",
    "b30hz70 = pd.read_csv(input_path + \"/BrokenTooth/b30hz70.csv\")\n",
    "b30hz80 = pd.read_csv(input_path + \"/BrokenTooth/b30hz80.csv\")\n",
    "b30hz90 = pd.read_csv(input_path + \"/BrokenTooth/b30hz90.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to compute aggregated features: standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdev_features(df, grouped, load, outcome):\n",
    "    #### Create empty dataframe with columns a1,a2,a3,a4\n",
    "    df_result = pd.DataFrame( [ np.zeros(len(df.columns)-2) ],columns= df.columns[:-2])\n",
    "\n",
    "    #### Aggregate in groups of nrows computing the standard deviation\n",
    "    # Remove load & failure columns, keeping only a1,a2,a3,a4\n",
    "    stdev_lenght=len(df.columns)-2\n",
    "    \n",
    "    #### Compute number of rows of the aggregated dataframe\n",
    "    nrows_raw = len(df.index)\n",
    "    nrows = math.floor(nrows_raw / grouped)\n",
    "    nrows_dropped = nrows_raw - nrows*grouped\n",
    "    print(\"nrows_raw=\", nrows_raw, \"   nrows=\", nrows, \"   Number of dropped rows of grouped= \", nrows_dropped/grouped*100,\"%\\n\")\n",
    "    \n",
    "    # Iterate every 'grouped' rows and compute stdev per column\n",
    "    for i in range(nrows):\n",
    "      df_group = df.iloc[i*grouped:i*grouped+grouped,:]\n",
    "      df_stdev = pd.DataFrame(df_group.std()).transpose()\n",
    "      # Remove load & failure columns\n",
    "      df_stdev=df_stdev.iloc[:,:stdev_lenght]\n",
    "      # Add row of calculated stdev\n",
    "      df_result = df_result.append(df_stdev, ignore_index=True)\n",
    "\n",
    "      #print (\"i*grouped TO i*grouped+grouped\", i*grouped, i*grouped+grouped)\n",
    "      #print (\"row, df_stdev=\\n\", row, df_stdev.iloc[:,:])\n",
    "      #print (\"df_result=\\n\", df_result)\n",
    "      #print(\"row\", i, \"\\n\", df_group)\n",
    "\n",
    "\n",
    "    # Remove the first row (it was the seed of zeros for initializing df_result)\n",
    "    #print(df_result)\n",
    "    df_result = df_result.iloc[1:,:]\n",
    "    # Add the column for 'load'\n",
    "    df_result['load'] = load*np.ones((nrows,1))\n",
    "\n",
    "    # Add the column for 'failure'\n",
    "    failure = np.ones((nrows,1))\n",
    "    df_result['failure'] = outcome\n",
    "    #print(df_result)\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broken, Load 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrows_raw= 94208    nrows= 942    Number of dropped rows of grouped=  8.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [H.5] DATASET BROKEN, 50% LOAD\n",
    "load = 50\n",
    "\n",
    "# CREATE THE COLUMN FOR 'load'\n",
    "## Expressed as %\n",
    "b30hz50['load'] = load\n",
    "\n",
    "# CREATE THE COLUMN FOR 'failure'\n",
    "##   0 is healthy\n",
    "##   1 is broken\n",
    "failure = 1\n",
    "b30hz50['failure'] = failure\n",
    "\n",
    "b30hz50_stdev= stdev_features (df = b30hz50, grouped= grouped, load= load, outcome= failure)\n",
    "b30hz50_stdev.describe()\n",
    "\n",
    "# Save to file\n",
    "b30hz50_stdev.to_csv(output_path + 'broken30hz50.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Healthy, Load 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrows_raw= 110848    nrows= 1108    Number of dropped rows of grouped=  48.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [B.5] DATASET HEALTHY, 50% LOAD\n",
    "load = 50\n",
    "h30hz50['load'] = load\n",
    "failure = 0\n",
    "h30hz50['failure'] = failure\n",
    "\n",
    "h30hz50_stdev= stdev_features (df = h30hz50, grouped= grouped, load= load, outcome= failure)\n",
    "h30hz50_stdev.describe()\n",
    "\n",
    "# Save to file\n",
    "h30hz50_stdev.to_csv(output_path + 'healthy30hz50.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load  0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrows_raw= 88320    nrows= 883    Number of dropped rows of grouped=  20.0 %\n",
      "\n",
      "nrows_raw= 88832    nrows= 888    Number of dropped rows of grouped=  32.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Broken dataset\n",
    "load = 0\n",
    "failure = 1\n",
    "filename = 'broken30hz0.csv'\n",
    "df = b30hz0\n",
    "\n",
    "b30hz0['load'] = load\n",
    "b30hz0['failure'] = failure\n",
    "b30hz0_stdev = stdev_features (df = df, grouped= grouped, load= load, outcome= failure)\n",
    "b30hz0_stdev.to_csv(output_path + filename, index = False)\n",
    "\n",
    "# Healthy dataset\n",
    "load = 0\n",
    "failure = 0\n",
    "filename = 'healthy30hz0.csv'\n",
    "df = h30hz0\n",
    "\n",
    "h30hz0['load'] = load\n",
    "h30hz0['failure'] = failure\n",
    "h30hz0_stdev = stdev_features (df = df, grouped= grouped, load= load, outcome= failure)\n",
    "h30hz0_stdev.to_csv(output_path + filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrows_raw= 105728    nrows= 1057    Number of dropped rows of grouped=  28.000000000000004 %\n",
      "\n",
      "nrows_raw= 106752    nrows= 1067    Number of dropped rows of grouped=  52.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Broken dataset\n",
    "load = 90\n",
    "failure = 1\n",
    "filename = 'broken30hz90.csv'\n",
    "df = b30hz90\n",
    "\n",
    "b30hz90['load'] = load\n",
    "b30hz90['failure'] = failure\n",
    "b30hz90_stdev = stdev_features (df = df, grouped= grouped, load= load, outcome= failure)\n",
    "b30hz90_stdev.to_csv(output_path + filename, index = False)\n",
    "\n",
    "# Healthy dataset\n",
    "load = 90\n",
    "failure = 0\n",
    "filename = 'healthy30hz90.csv'\n",
    "df = h30hz90\n",
    "\n",
    "h30hz90['load'] = load\n",
    "h30hz90['failure'] = failure\n",
    "h30hz90_stdev = stdev_features (df = df, grouped= grouped, load= load, outcome= failure)\n",
    "h30hz90_stdev.to_csv(output_path + filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrows_raw= 111616    nrows= 1116    Number of dropped rows of grouped=  16.0 %\n",
      "\n",
      "nrows_raw= 92928    nrows= 929    Number of dropped rows of grouped=  28.000000000000004 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Broken dataset\n",
    "load = 10\n",
    "failure = 1\n",
    "filename = 'broken30hz10.csv'\n",
    "df = b30hz10\n",
    "\n",
    "b30hz10['load'] = load\n",
    "b30hz10['failure'] = failure\n",
    "b30hz10_stdev = stdev_features (df = df, grouped= grouped, load= load, outcome= failure)\n",
    "b30hz10_stdev.to_csv(output_path + filename, index = False)\n",
    "\n",
    "# Healthy dataset\n",
    "load = 10\n",
    "failure = 0\n",
    "filename = 'healthy30hz10.csv'\n",
    "df = h30hz10\n",
    "\n",
    "h30hz10['load'] = load\n",
    "h30hz10['failure'] = failure\n",
    "h30hz10_stdev = stdev_features (df = df, grouped= grouped, load= load, outcome= failure)\n",
    "h30hz10_stdev.to_csv(output_path + filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrows_raw= 114432    nrows= 1144    Number of dropped rows of grouped=  32.0 %\n",
      "\n",
      "nrows_raw= 108544    nrows= 1085    Number of dropped rows of grouped=  44.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Broken dataset\n",
    "load = 20\n",
    "failure = 1\n",
    "filename = 'broken30hz20.csv'\n",
    "df = b30hz20\n",
    "\n",
    "b30hz20['load'] = load\n",
    "b30hz20['failure'] = failure\n",
    "b30hz20_stdev = stdev_features (df = df, grouped= grouped, load= load, outcome= failure)\n",
    "b30hz20_stdev.to_csv(output_path + filename, index = False)\n",
    "\n",
    "# Healthy dataset\n",
    "load = 20\n",
    "failure = 0\n",
    "filename = 'healthy30hz20.csv'\n",
    "df = h30hz20\n",
    "\n",
    "h30hz20['load'] = load\n",
    "h30hz20['failure'] = failure\n",
    "h30hz20_stdev = stdev_features (df = df, grouped= grouped, load= load, outcome= failure)\n",
    "h30hz20_stdev.to_csv(output_path + filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrows_raw= 89856    nrows= 898    Number of dropped rows of grouped=  56.00000000000001 %\n",
      "\n",
      "nrows_raw= 106240    nrows= 1062    Number of dropped rows of grouped=  40.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Broken dataset\n",
    "load = 30\n",
    "failure = 1\n",
    "filename = 'broken30hz30.csv'\n",
    "df = b30hz30\n",
    "\n",
    "b30hz30['load'] = load\n",
    "b30hz30['failure'] = failure\n",
    "b30hz30_stdev = stdev_features (df = df, grouped= grouped, load= load, outcome= failure)\n",
    "b30hz30_stdev.to_csv(output_path + filename, index = False)\n",
    "\n",
    "# Healthy dataset\n",
    "load = 30\n",
    "failure = 0\n",
    "filename = 'healthy30hz30.csv'\n",
    "df = h30hz30\n",
    "\n",
    "h30hz30['load'] = load\n",
    "h30hz30['failure'] = failure\n",
    "h30hz30_stdev = stdev_features (df = df, grouped= grouped, load= load, outcome= failure)\n",
    "h30hz30_stdev.to_csv(output_path + filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrows_raw= 94464    nrows= 944    Number of dropped rows of grouped=  64.0 %\n",
      "\n",
      "nrows_raw= 100608    nrows= 1006    Number of dropped rows of grouped=  8.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Broken dataset\n",
    "load = 40\n",
    "failure = 1\n",
    "filename = 'broken30hz40.csv'\n",
    "df = b30hz40\n",
    "\n",
    "b30hz40['load'] = load\n",
    "b30hz40['failure'] = failure\n",
    "b30hz40_stdev = stdev_features (df = df, grouped= grouped, load= load, outcome= failure)\n",
    "b30hz40_stdev.to_csv(output_path + filename, index = False)\n",
    "\n",
    "# Healthy dataset\n",
    "load = 40\n",
    "failure = 0\n",
    "filename = 'healthy30hz40.csv'\n",
    "df = h30hz40\n",
    "\n",
    "h30hz40['load'] = load\n",
    "h30hz40['failure'] = failure\n",
    "h30hz40_stdev = stdev_features (df = df, grouped= grouped, load= load, outcome= failure)\n",
    "h30hz40_stdev.to_csv(output_path + filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrows_raw= 95488    nrows= 954    Number of dropped rows of grouped=  88.0 %\n",
      "\n",
      "nrows_raw= 99840    nrows= 998    Number of dropped rows of grouped=  40.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Broken dataset\n",
    "load = 60\n",
    "failure = 1\n",
    "filename = 'broken30hz60.csv'\n",
    "df = b30hz60\n",
    "\n",
    "b30hz60['load'] = load\n",
    "b30hz60['failure'] = failure\n",
    "b30hz60_stdev = stdev_features (df = df, grouped= grouped, load= load, outcome= failure)\n",
    "b30hz60_stdev.to_csv(output_path + filename, index = False)\n",
    "\n",
    "# Healthy dataset\n",
    "load = 60\n",
    "failure = 0\n",
    "filename = 'healthy30hz60.csv'\n",
    "df = h30hz60\n",
    "\n",
    "h30hz60['load'] = load\n",
    "h30hz60['failure'] = failure\n",
    "h30hz60_stdev = stdev_features (df = df, grouped= grouped, load= load, outcome= failure)\n",
    "h30hz60_stdev.to_csv(output_path + filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrows_raw= 100864    nrows= 1008    Number of dropped rows of grouped=  64.0 %\n",
      "\n",
      "nrows_raw= 101376    nrows= 1013    Number of dropped rows of grouped=  76.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Broken dataset\n",
    "load = 70\n",
    "failure = 1\n",
    "filename = 'broken30hz70.csv'\n",
    "df = b30hz70\n",
    "\n",
    "b30hz70['load'] = load\n",
    "b30hz70['failure'] = failure\n",
    "b30hz70_stdev = stdev_features (df = df, grouped= grouped, load= load, outcome= failure)\n",
    "b30hz70_stdev.to_csv(output_path + filename, index = False)\n",
    "\n",
    "# Healthy dataset\n",
    "load = 70\n",
    "failure = 0\n",
    "filename = 'healthy30hz70.csv'\n",
    "df = h30hz70\n",
    "\n",
    "h30hz70['load'] = load\n",
    "h30hz70['failure'] = failure\n",
    "h30hz70_stdev = stdev_features (df = df, grouped= grouped, load= load, outcome= failure)\n",
    "h30hz70_stdev.to_csv(output_path + filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrows_raw= 110335    nrows= 1103    Number of dropped rows of grouped=  35.0 %\n",
      "\n",
      "nrows_raw= 99840    nrows= 998    Number of dropped rows of grouped=  40.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Broken dataset\n",
    "load = 80\n",
    "failure = 1\n",
    "filename = 'broken30hz80.csv'\n",
    "df = b30hz80\n",
    "\n",
    "b30hz80['load'] = load\n",
    "b30hz80['failure'] = failure\n",
    "b30hz80_stdev = stdev_features (df = df, grouped= grouped, load= load, outcome= failure)\n",
    "b30hz80_stdev.to_csv(output_path + filename, index = False)\n",
    "\n",
    "# Healthy dataset\n",
    "load = 80\n",
    "failure = 0\n",
    "filename = 'healthy30hz80.csv'\n",
    "df = h30hz80\n",
    "\n",
    "h30hz80['load'] = load\n",
    "h30hz80['failure'] = failure\n",
    "h30hz80_stdev = stdev_features (df = df, grouped= grouped, load= load, outcome= failure)\n",
    "h30hz80_stdev.to_csv(output_path + filename, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
